import { NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { v4 as uuidv4 } from 'uuid';
import fs from 'fs';
import path from 'path';
import os from 'os';
import { createReadStream } from 'fs';
import { cookies } from 'next/headers';
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';
import { OpenAIEmbeddings } from '@langchain/openai';
import { exec } from 'child_process';
import { promisify } from 'util';
import { createClient as createDeepgramClient } from '@deepgram/sdk';

const execPromise = promisify(exec);

// Initialize Deepgram client
const deepgram = createDeepgramClient(process.env.DEEPGRAM_API_KEY || '');

// Initialize Supabase client
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!;

// OpenAI Whisper API has a 25MB file size limit
const MAX_WHISPER_FILE_SIZE = 25 * 1024 * 1024; // 25MB in bytes

// Maximum file size for processing
const MAX_FILE_SIZE = 100 * 1024 * 1024; // 100MB (Deepgram handles much larger files than Whisper)

// Function to create audio_files table if it doesn't exist
async function createAudioFilesTable(supabase: any) {
  try {
    console.log('üîç [DEBUG API] Attempting to create audio_files table');
    
    // First, check if the table already exists
    try {
      const { data, error } = await supabase
        .from('audio_files')
        .select('id')
        .limit(1);
      
      if (!error) {
        console.log('üîç [DEBUG API] audio_files table already exists');
        return true;
      }
    } catch (e) {
      console.log('üîç [DEBUG API] Table does not exist, will create it');
    }
    
    // SQL to create the audio_files table
    const createTableSQL = `
      CREATE TABLE IF NOT EXISTS audio_files (
        id UUID PRIMARY KEY,
        user_id UUID NOT NULL,
        file_url TEXT NOT NULL,
        original_name TEXT NOT NULL,
        transcription_status TEXT NOT NULL,
        transcription_text TEXT,
        document_id UUID,
        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
      );
    `;
    
    // Try different methods to create the table
    try {
      // Method 1: Using exec_sql RPC
      console.log('üîç [DEBUG API] Trying to create table using exec_sql RPC');
      const { error: rpcError } = await supabase.rpc('exec_sql', { sql_query: createTableSQL });
      
      if (rpcError) {
        console.error('üîç [DEBUG API] RPC error creating table:', rpcError);
        
        // Method 2: Direct SQL query using REST API
        console.log('üîç [DEBUG API] Trying direct REST API for table creation');
        const { error: restError } = await supabase.rest.sql.query(createTableSQL);
        
        if (restError) {
          console.error('üîç [DEBUG API] REST API error creating table:', restError);
          
          // Method 3: Try a simpler table structure
          console.log('üîç [DEBUG API] Trying simplified table structure');
          const simpleCreateSQL = `
            CREATE TABLE IF NOT EXISTS audio_files (
              id UUID PRIMARY KEY,
              user_id TEXT NOT NULL,
              transcription_text TEXT,
              document_id UUID
            );
          `;
          
          const { error: simpleError } = await supabase.rpc('exec_sql', { sql_query: simpleCreateSQL });
          
          if (simpleError) {
            console.error('üîç [DEBUG API] Error with simplified table creation:', simpleError);
            return false;
          }
        }
      }
      
      // Verify the table exists
      try {
        const { data, error } = await supabase
          .from('audio_files')
          .select('id')
          .limit(1);
        
        if (error) {
          console.error('üîç [DEBUG API] Table verification failed:', error);
          return false;
        }
        
        console.log('üîç [DEBUG API] audio_files table created and verified');
        return true;
      } catch (e) {
        console.error('üîç [DEBUG API] Table verification failed with exception:', e);
        return false;
      }
    } catch (e) {
      console.error('üîç [DEBUG API] Table creation exception:', e);
      return false;
    }
  } catch (e) {
    console.error('üîç [DEBUG API] Unexpected error creating audio_files table:', e);
    return false;
  }
}

// Function to compress audio file using ffmpeg
async function compressAudioFile(inputPath: string): Promise<string> {
  const outputPath = `${inputPath}_compressed.mp3`;
  
  try {
    console.log('üîç [DEBUG API] Compressing audio file with ffmpeg');
    // Use ffmpeg to compress the audio file
    // -y: Overwrite output file without asking
    // -i: Input file
    // -b:a: Audio bitrate (64k = 64 kbps)
    // -ac: Number of audio channels (1 = mono)
    // -ar: Audio sample rate (22050 Hz)
    await execPromise(`ffmpeg -y -i "${inputPath}" -b:a 64k -ac 1 -ar 22050 "${outputPath}"`);
    
    // Check if the compressed file exists and get its size
    const stats = fs.statSync(outputPath);
    console.log('üîç [DEBUG API] Compressed file size:', stats.size, 'bytes');
    
    return outputPath;
  } catch (error) {
    console.error('üîç [DEBUG API] Error compressing audio file:', error);
    throw new Error('Failed to compress audio file');
  }
}

// Function to split audio file into chunks if it's still too large
async function splitAudioIfNeeded(inputPath: string): Promise<string[]> {
  const stats = fs.statSync(inputPath);
  
  // If file is under the limit, return it as is
  if (stats.size <= MAX_WHISPER_FILE_SIZE) {
    return [inputPath];
  }
  
  console.log('üîç [DEBUG API] Audio file still too large after compression, splitting into chunks');
  
  // Calculate duration using ffprobe
  const { stdout } = await execPromise(`ffprobe -i "${inputPath}" -show_entries format=duration -v quiet -of csv="p=0"`);
  const duration = parseFloat(stdout.trim());
  
  // Calculate how many chunks we need (aim for 20MB per chunk to be safe)
  const chunkCount = Math.ceil(stats.size / (20 * 1024 * 1024));
  const chunkDuration = duration / chunkCount;
  
  console.log(`üîç [DEBUG API] Splitting ${duration}s audio into ${chunkCount} chunks of ~${chunkDuration}s each`);
  
  const outputPaths: string[] = [];
  
  // Split the file into chunks
  for (let i = 0; i < chunkCount; i++) {
    const startTime = i * chunkDuration;
    const outputPath = `${inputPath}_part${i}.mp3`;
    
    await execPromise(`ffmpeg -y -i "${inputPath}" -ss ${startTime} -t ${chunkDuration} -c copy "${outputPath}"`);
    outputPaths.push(outputPath);
    
    console.log(`üîç [DEBUG API] Created chunk ${i+1}/${chunkCount}: ${outputPath}`);
  }
  
  return outputPaths;
}

// Replace the old transcribeAudio function with this new Deepgram implementation
async function transcribeAudioWithDeepgram(filePath: string): Promise<string> {
  console.log('üîç [DEBUG API] Transcribing with Deepgram API:', path.basename(filePath));
  
  try {
    // Use createReadStream for efficient streaming
    const audioFile = fs.readFileSync(filePath);
    
    // Call Deepgram API
    const { result, error } = await deepgram.listen.prerecorded.transcribeFile(
      audioFile,
      {
        model: 'nova-3', // Nova is Deepgram's best model
        smart_format: true, // Adds punctuation and capitalization
        diarize: true, // Separates speakers
        paragraphs: true, // Groups text into paragraphs
        utterances: true, // Segments audio by speaker turns
        punctuate: true, // Adds punctuation
      }
    );

    if (error) {
      console.error('üîç [DEBUG API] Deepgram transcription error:', error);
      throw error;
    }

    // Extract the transcript text from the result
    if (result && result.results && result.results.channels && result.results.channels[0]) {
      const transcript = result.results.channels[0].alternatives[0].transcript;
      console.log(`üîç [DEBUG API] Transcription complete (${transcript.length} chars): "${transcript.substring(0, 100)}..."`);
      return transcript;
    } else {
      throw new Error('No transcription found in Deepgram response');
    }
  } catch (error) {
    console.error('üîç [DEBUG API] Transcription error:', error);
    throw error;
  }
}

// Add this function to validate audio files before sending to Deepgram
async function validateAudioFile(filePath: string): Promise<{ isValid: boolean; details: string }> {
  try {
    // Check if file exists
    if (!fs.existsSync(filePath)) {
      return { isValid: false, details: 'File does not exist' };
    }
    
    // Check file size
    const stats = fs.statSync(filePath);
    if (stats.size === 0) {
      return { isValid: false, details: 'File is empty' };
    }
    
    if (stats.size > MAX_FILE_SIZE) {
      return { 
        isValid: false, 
        details: `File size (${(stats.size / (1024 * 1024)).toFixed(2)}MB) exceeds maximum allowed size (100MB)` 
      };
    }
    
    // Get file extension
    const ext = path.extname(filePath).toLowerCase().substring(1);
    const supportedFormats = ['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'webm'];
    if (!supportedFormats.includes(ext)) {
      return { 
        isValid: false, 
        details: `File format '${ext}' is not supported. Supported formats: ${supportedFormats.join(', ')}` 
      };
    }
    
    // Use ffprobe to get file info (this will validate if it's a proper audio file)
    try {
      const { stdout, stderr } = await execPromise(`ffprobe -v error -show_format -show_streams -print_format json "${filePath}"`);
      
      if (stderr) {
        console.log('üîç [DEBUG API] ffprobe stderr:', stderr);
      }
      
      const fileInfo = JSON.parse(stdout);
      console.log('üîç [DEBUG API] Audio file info:', JSON.stringify({
        format: fileInfo.format.format_name,
        duration: fileInfo.format.duration,
        bitrate: fileInfo.format.bit_rate,
        size: fileInfo.format.size,
        codec: fileInfo.streams?.[0]?.codec_name,
        channels: fileInfo.streams?.[0]?.channels,
        sample_rate: fileInfo.streams?.[0]?.sample_rate
      }, null, 2));
      
      // Check if it's actually an audio file
      const hasAudioStream = fileInfo.streams?.some((stream: any) => stream.codec_type === 'audio');
      if (!hasAudioStream) {
        return { isValid: false, details: 'File does not contain audio streams' };
      }
      
      return { isValid: true, details: 'File is valid' };
    } catch (error) {
      // ffprobe failed, which means the file might be corrupt or not a proper audio file
      return { isValid: false, details: `File validation failed: ${error}` };
    }
  } catch (error) {
    return { isValid: false, details: `Error validating file: ${error}` };
  }
}

async function ensureAudioFilesTableHasDocumentIdColumn(supabase: any) {
  try {
    console.log('üîç [DEBUG API] Checking if audio_files table has document_id column');
    
    // Try to alter the table if needed
    const alterTableSQL = `
      ALTER TABLE IF EXISTS audio_files 
      ADD COLUMN IF NOT EXISTS document_id UUID;
    `;
    
    try {
      // Method 1: Using exec_sql RPC
      const { error: rpcError } = await supabase.rpc('exec_sql', { sql_query: alterTableSQL });
      
      if (rpcError) {
        console.error('üîç [DEBUG API] RPC error adding document_id column:', rpcError);
        
        // Method 2: Direct SQL query using REST API
        const { error: restError } = await supabase.rest.sql.query(alterTableSQL);
        
        if (restError) {
          console.error('üîç [DEBUG API] REST API error adding document_id column:', restError);
          return false;
        }
      }
      
      console.log('üîç [DEBUG API] Ensured document_id column exists in audio_files table');
      return true;
    } catch (e) {
      console.error('üîç [DEBUG API] Error ensuring document_id column exists:', e);
      return false;
    }
  } catch (e) {
    console.error('üîç [DEBUG API] Unexpected error checking for document_id column:', e);
    return false;
  }
}

export async function POST(request: Request) {
  console.log("üîç [DEBUG API] process-audio-file API called");
  
  try {
    // Extract request data
    let body;
    try {
      body = await request.json();
      console.log("üîç [DEBUG API] Request body:", body);
    } catch (error) {
      console.error("üîç [DEBUG API] Error parsing request body:", error);
      return NextResponse.json({
        status: 'failed',
        error: 'Invalid request format',
        details: error instanceof Error ? error.message : 'Unknown parsing error'
      }, { status: 400 });
    }
    
    const { filePath, fileName } = body;
    
    if (!filePath || !fileName) {
      console.error("üîç [DEBUG API] Missing required parameters:", { filePath, fileName });
      return NextResponse.json({
        status: 'failed',
        error: 'Missing required parameters',
        details: 'Both filePath and fileName are required'
      }, { status: 400 });
    }
    
    // Array to track temporary files for cleanup
    const tempFiles: string[] = [];
    
    // Initialize Supabase client
    const supabase = createClient(supabaseUrl, supabaseServiceKey);
    
    // Get authenticated user or use anonymous ID
    const userId = '00000000-0000-0000-0000-000000000000'; // Replace with actual auth logic if needed
    console.log('üîç [DEBUG API] User authentication:', userId);
    
    // Try to get the actual user ID from cookies
    let actualUserId = userId;
    try {
      // Skip cookie extraction for now due to TypeScript issues
      // Just use the default user ID
      console.log('üîç [DEBUG API] Using default user ID:', actualUserId);
    } catch (e) {
      console.error('üîç [DEBUG API] Error extracting user ID:', e);
      // Continue with the default user ID
    }
    
    console.log('üîç [DEBUG API] Processing audio file:', {
      filePath,
      fileName,
      userId: actualUserId
    });
    
    // Download the file from Supabase Storage
    console.log('üîç [DEBUG API] Downloading file from storage:', filePath);
    const { data: fileData, error: fileError } = await supabase.storage
      .from('Documents')
      .download(filePath);
    
    if (fileError || !fileData) {
      console.error('üîç [DEBUG API] File download error:', fileError);
      return NextResponse.json(
        { error: 'Failed to download audio file from storage' },
        { status: 500 }
      );
    }
    
    console.log('üîç [DEBUG API] File loaded, size:', fileData.size);
    
    // Check if file size exceeds OpenAI's limit
    if (fileData.size > MAX_FILE_SIZE) {
      console.log('üîç [DEBUG API] File size exceeds Deepgram limit, will compress/split');
    }
    
    // Save file to temporary location for transcription
    const tempDir = os.tmpdir();
    const tempFilePath = path.join(tempDir, path.basename(filePath));
    
    // Convert Blob to Buffer and write to disk
    const buffer = Buffer.from(await fileData.arrayBuffer());
    fs.writeFileSync(tempFilePath, buffer);
    
    // Create an audio record with 'processing' status first
    const audioId = uuidv4();
    let audioInsertSuccess = false;
    
    try {
      console.log('üîç [DEBUG API] Creating initial audio record with processing status, ID:', audioId);
      
      const initialAudioData = {
        id: audioId,
        user_id: actualUserId,
        file_url: filePath,
        original_name: fileName,
        transcription_status: 'processing',
        transcription_text: ''
      };
      
      // Try to insert the initial record
      const { error: audioInitError } = await supabase
        .from('audio_files')
        .insert([initialAudioData]);
      
      if (audioInitError) {
        console.error('üîç [DEBUG API] Initial audio record creation error:', audioInitError);
        
        // If the table doesn't exist, try to create it
        if (audioInitError.message && audioInitError.message.includes('relation "audio_files" does not exist')) {
          console.log('üîç [DEBUG API] audio_files table does not exist, attempting to create it');
          
          const tableCreated = await createAudioFilesTable(supabase);
          if (tableCreated) {
            // Also make sure the document_id column exists
            await ensureAudioFilesTableHasDocumentIdColumn(supabase);
          }
          
          if (tableCreated) {
            console.log('üîç [DEBUG API] Created audio_files table, trying insertion again');
            
            // Try insertion again
            const { error: retryError } = await supabase
              .from('audio_files')
              .insert([initialAudioData]);
            
            if (retryError) {
              console.error('üîç [DEBUG API] Retry initial audio record creation error:', retryError);
            } else {
              console.log('üîç [DEBUG API] Initial audio record created on retry, ID:', audioId);
            }
          }
        }
      } else {
        console.log('üîç [DEBUG API] Initial audio record created with processing status, ID:', audioId);
      }
    } catch (e) {
      console.error('üîç [DEBUG API] Unexpected error during initial audio record creation:', e);
    }
    
    // Create a document entry for the transcription
    const documentId = uuidv4();
    let documentCreatedSuccessfully = false;
    
    try {
      // Check if we need to include the audio_id in the document
      const { data: checkColumns } = await supabase.from('Documents').select('*').limit(1);
      
      // Check if audio_id column exists in the response
      const hasAudioIdColumn = checkColumns && checkColumns[0] && 'audio_id' in checkColumns[0];
      console.log('üîç [DEBUG API] Documents table has audio_id column:', hasAudioIdColumn);
      
      // Create document entry with or without audio_id based on schema
      const documentEntry: any = {
        id: documentId,
        user_id: actualUserId, // Use the actual user ID
        file_url: filePath,
        original_name: `Transcription: ${fileName}`
      };
      
      // Always add the audio_id if the column exists
      if (hasAudioIdColumn) {
        documentEntry.audio_id = audioId;
        console.log('üîç [DEBUG API] Adding audio_id to document:', audioId);
      }
      
      // Check if the Documents table has an uploaded_at column
      const hasUploadedAtColumn = checkColumns && checkColumns[0] && 'uploaded_at' in checkColumns[0];
      if (hasUploadedAtColumn) {
        documentEntry.uploaded_at = new Date().toISOString();
      }
      
      // Check if the Documents table has a created_at column
      const hasCreatedAtColumn = checkColumns && checkColumns[0] && 'created_at' in checkColumns[0];
      if (!hasCreatedAtColumn) {
        // If there's no created_at column (which might be auto-generated), add it
        documentEntry.created_at = new Date().toISOString();
      }
      
      console.log('üîç [DEBUG API] Inserting document with data:', documentEntry);
      
      const { data: insertedDoc, error: documentError } = await supabase
        .from('Documents')
        .insert([documentEntry])
        .select();
      
      if (documentError) {
        console.error('üîç [DEBUG API] Document insertion error:', documentError);
        throw new Error('Failed to create document for transcription: ' + documentError.message);
      }
      
      documentCreatedSuccessfully = true;
      console.log('üîç [DEBUG API] Document created for transcription, ID:', documentId);
      console.log('üîç [DEBUG API] Inserted document data:', insertedDoc);
      
      // Verify the document was created by trying to fetch it
      const { data: verifyDoc, error: verifyError } = await supabase
        .from('Documents')
        .select('*')
        .eq('id', documentId)
        .single();
      
      if (verifyError) {
        console.error('üîç [DEBUG API] Document verification error:', verifyError);
      } else {
        console.log('üîç [DEBUG API] Document verified successfully:', verifyDoc);
      }
      
      // If there's no audio_id column in the Documents table, we need to update the audio record
      // to store the document_id instead for proper linking
      if (!hasAudioIdColumn) {
        console.log('üîç [DEBUG API] No audio_id column in Documents, updating audio_files with document_id');
        try {
          const { error: audioUpdateError } = await supabase
            .from('audio_files')
            .update({ document_id: documentId })
            .eq('id', audioId);
          
          if (audioUpdateError) {
            console.error('üîç [DEBUG API] Error updating audio record with document_id:', audioUpdateError);
          } else {
            console.log('üîç [DEBUG API] Updated audio record with document_id:', documentId);
          }
        } catch (e) {
          console.error('üîç [DEBUG API] Error during audio record update with document_id:', e);
        }
      }
      
      // Now perform the actual transcription
      let transcriptionText = '';
      let transcriptionStatus = 'completed';
      
      try {
        // Compress the audio file if it's too large
        if (fileData.size > MAX_FILE_SIZE) {
          const compressedFilePath = await compressAudioFile(tempFilePath);
          
          // Split the file if it's still too large after compression
          const audioChunks = await splitAudioIfNeeded(compressedFilePath);
          audioChunks.forEach(chunk => {
            if (chunk !== compressedFilePath) tempFiles.push(chunk);
          });
          
          // Transcribe all chunks and combine
          transcriptionText = await transcribeAudioWithDeepgram(compressedFilePath);
        } else {
          // File is small enough, transcribe directly
          console.log('üîç [DEBUG API] Transcribing audio file directly...');
          try {
            // Validate the file before sending to Deepgram
            const validation = await validateAudioFile(tempFilePath);
            if (!validation.isValid) {
              throw new Error(`Audio file validation failed: ${validation.details}`);
            }
            
            console.log('üîç [DEBUG API] Audio file validated successfully, proceeding with Deepgram transcription');
            
            // Log API key length for diagnostic purposes (don't log the actual key)
            console.log('üîç [DEBUG API] Deepgram API key length:', process.env.DEEPGRAM_API_KEY?.length || 'undefined');
            
            try {
              // Transcribe using Deepgram
              transcriptionText = await transcribeAudioWithDeepgram(tempFilePath);
              console.log(`üîç [DEBUG API] Transcription complete (${transcriptionText.length} chars)`);
            } catch (apiError: any) {
              // Handle specific Deepgram errors
              console.error('üîç [DEBUG API] Deepgram API error:', apiError);
              transcriptionStatus = 'failed';
              
              // Check if this is a quota/billing error
              if (apiError.message?.includes('quota') || 
                  apiError.message?.includes('billing') ||
                  apiError.message?.includes('limit exceeded') ||
                  apiError.status === 429) {
                console.error('üîç [DEBUG API] Deepgram quota exceeded or billing error:', apiError);
                throw new Error('Deepgram API quota exceeded. Please check your billing details.');
              }
              
              // Handle connection errors
              if (apiError.message?.includes('ECONNRESET') || 
                  apiError.message?.includes('Connection error') ||
                  apiError.cause?.code === 'ECONNRESET') {
                console.error('üîç [DEBUG API] Network connection error:', apiError);
                throw new Error('Network connection error while calling Deepgram. Please try again later.');
              }
              
              throw apiError;
            }
          } catch (directError) {
            console.error('üîç [DEBUG API] Transcription error:', directError);
            transcriptionStatus = 'failed';
            
            // Use a placeholder and report the error
            transcriptionText = "Audio transcription failed. Error: " + ((directError as Error).message || "Unknown error");
            console.log('üîç [DEBUG API] Using placeholder text for transcription failure');
            throw directError;
          }
        }
        
        console.log('üîç [DEBUG API] Transcription complete, length:', transcriptionText.length);
      } catch (error: any) {
        console.error('üîç [DEBUG API] Transcription error:', error);
        transcriptionStatus = 'failed';
        
        // Check for specific OpenAI errors
        if (error?.status === 413) {
          return NextResponse.json(
            { 
              error: 'Audio file too large for processing', 
              message: 'The audio file exceeds the maximum size limit. Please upload a smaller file or compress it before uploading.',
              status: 'failed'
            },
            { status: 413 }
          );
        }
        
        // Check for file format errors
        if (error.message && (
          error.message.includes('Invalid file format') || 
          error.message.includes('Unsupported file type') ||
          error.message.includes('File is empty')
        )) {
          return NextResponse.json(
            { 
              error: 'Invalid audio file format', 
              message: 'The audio file format is not supported or the file is corrupted. Please upload a valid MP3, WAV, or M4A file.',
              status: 'failed'
            },
            { status: 400 }
          );
        }
        
        // Check for API key errors
        if (error.message && error.message.includes('API key')) {
          console.error('üîç [DEBUG API] API key error:', error.message);
          return NextResponse.json(
            { 
              error: 'Transcription service unavailable', 
              message: 'The audio transcription service is currently unavailable. Please try again later.',
              status: 'failed'
            },
            { status: 503 }
          );
        }
        
        // Generic error response
        return NextResponse.json(
          { 
            error: 'Failed to transcribe audio', 
            message: 'An error occurred while transcribing the audio file. Please try again or upload a different file.',
            details: String(error),
            status: 'failed'
          },
          { status: 500 }
        );
      }
      
      // Update the audio record with the transcription and status
      try {
        console.log('üîç [DEBUG API] Updating audio record with transcription, ID:', audioId);
        
        // First update the audio_files table
        const { data: updatedAudio, error: audioUpdateError } = await supabase
          .from('audio_files')
          .update({
            transcription_text: transcriptionText,
            transcription_status: transcriptionStatus
          })
          .eq('id', audioId)
          .select();
        
        if (audioUpdateError) {
          console.error('üîç [DEBUG API] Audio record update error:', audioUpdateError);
          throw new Error(`Failed to update audio record: ${audioUpdateError.message}`);
        } else {
          audioInsertSuccess = true;
          console.log('üîç [DEBUG API] Audio metadata saved successfully in audio_files table, ID:', audioId);
          
          // Now also update the Document record with the transcription and status
          console.log('üîç [DEBUG API] Updating Document record with transcription content, ID:', documentId);
          
          // Check if the document exists first
          const { data: docCheck, error: docCheckError } = await supabase
            .from('Documents')
            .select('id, audio_id')
            .eq('id', documentId)
            .single();
            
          if (docCheckError) {
            console.error('üîç [DEBUG API] Error checking document:', docCheckError);
            // Don't throw an error, just log it and continue
            console.error(`Failed to check document: ${docCheckError.message}`);
          } else if (docCheck) {
            console.log('üîç [DEBUG API] Found document, updating with audio_id');
            
            // Check which columns exist in Documents table
            try {
              // First, try to update just the audio_id and status fields
              const updateData: any = { 
                audio_id: audioId,
                updated_at: new Date().toISOString()
              };
              
              // Don't try to update content or status since those columns don't exist
              const { error: docUpdateError } = await supabase
                .from('Documents')
                .update(updateData)
                .eq('id', documentId);
                
              if (docUpdateError) {
                console.error('üîç [DEBUG API] Error updating document with audio_id:', docUpdateError);
                console.log(`Could not update document: ${docUpdateError.message}`);
              } else {
                console.log('üîç [DEBUG API] Successfully updated document with audio_id');
              }
            } catch (updateError) {
              console.error('üîç [DEBUG API] Update document error:', updateError);
            }
          } else {
            console.error('üîç [DEBUG API] Document not found for ID:', documentId);
          }
        }
      } catch (e) {
        console.error('üîç [DEBUG API] Error during record updates:', e);
        
        // Continue processing anyway to return a response
        // Rather than failing completely, we'll let the client know
        // there was an issue with updating the records
      }
      
      // Store the transcription in document_vectors to ensure it's accessible
      console.log('üîç [DEBUG API] Splitting transcription into chunks');
      const textSplitter = new RecursiveCharacterTextSplitter({
        chunkSize: 1000,
        chunkOverlap: 200,
      });
      
      const chunks = await textSplitter.createDocuments([transcriptionText]);
      console.log('üîç [DEBUG API] Transcription split into', chunks.length, 'chunks');
      
      // Skip OpenAI embeddings completely
      console.log('üîç [DEBUG API] Skipping OpenAI embeddings due to quota issues');
      const embeddingsAvailable = false;
      
      // Generate embeddings and insert into vectors table (if available)
      console.log('üîç [DEBUG API] Generating embeddings and inserting vectors');
      let insertCount = 0;
      let errorCount = 0;
      
      // If embeddings failed or aren't available, use the fallback method
      // Note: We can't store full transcription text in document_vectors table as it has no content column
      console.log('üîç [DEBUG API] Cannot store transcription text directly as document_vectors has no content column');
      console.log('üîç [DEBUG API] Will rely on audio_files table for transcription storage');
      
      // Ensure the audio_files insertion was successful
      if (audioInsertSuccess) {
        console.log('üîç [DEBUG API] Transcription was successfully stored in audio_files table');
      } else {
        console.error('üîç [DEBUG API] Warning: Transcription may not be persisted in any table');
        console.log('üîç [DEBUG API] Transcription text (first 100 chars):', transcriptionText.substring(0, 100));
      }
      
      console.log('üîç [DEBUG API] Vector insertion complete:', { insertCount, errorCount });
      
      // Even if we had errors with embeddings, we still have a successful transcription
      return NextResponse.json({
        success: true,
        status: transcriptionStatus,
        message: 'Audio transcribed and processed successfully',
        documentId: documentId,
        audioId: audioId,
        isCreated: documentCreatedSuccessfully,
        audioInsertSuccess,
        chunkCount: chunks.length,
        insertedVectors: insertCount,
        embeddingsAvailable,
      });
      
    } catch (e) {
      console.error('üîç [DEBUG API] Unexpected error during transcription:', e);
      throw new Error('Failed to transcribe audio: ' + (e instanceof Error ? e.message : String(e)));
    }
  } catch (error) {
    console.error("üîç [DEBUG API] Unhandled error in audio processing:", error);
    return NextResponse.json({
      status: 'failed',
      error: 'Audio processing failed',
      details: error instanceof Error ? error.message : 'Unknown processing error',
      suggestion: 'This might be a temporary issue. Please try uploading a different audio file or try again later.'
    }, { status: 500 });
  }
} 